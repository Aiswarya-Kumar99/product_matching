{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xl3b_abVQpZ6"
      },
      "outputs": [],
      "source": [
        "!pip install pandas jsonlines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7imxdkqyW_nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "qtnF_3i0C3FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Convert a .json.gz into a pandas dataframe\n",
        "\n",
        "import pandas as pd\n",
        "import jsonlines\n",
        "import gzip # Import the gzip module\n",
        "\n",
        "def jsonl_to_dataframe(file_path):\n",
        "  \"\"\"Converts a JSONL file to a pandas DataFrame.\n",
        "\n",
        "  Args:\n",
        "    file_path: The path to the JSONL file.\n",
        "\n",
        "  Returns:\n",
        "    A pandas DataFrame representing the data in the JSONL file.\n",
        "  \"\"\"\n",
        "  data = []\n",
        "  # Open the gzipped file using gzip.open()\n",
        "  with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
        "    # Read the file line by line\n",
        "    for line in f:\n",
        "      # Parse each line as JSON and append to data list\n",
        "      data.append(json.loads(line))\n",
        "  return pd.DataFrame(data)\n",
        "\n",
        "# Example usage (replace with your actual file path)\n",
        "file_path = \"/content/drive/MyDrive/WDC/20pair/wdcproducts20cc80rnd000un_train_medium.json.gz\" # Example path, update as needed\n",
        "# file_path_test = \"/content/drive/MyDrive/WDC/80pair/wdcproducts80cc20rnd000un_valid_medium.json.gz\"\n",
        "# Assuming jsonl_to_dataframe is already defined and working\n",
        "df = jsonl_to_dataframe(file_path)\n",
        "\n",
        "# Append test DataFrame to train DataFrame\n",
        "# df = pd.concat([df_train, df_test], ignore_index=True)\n",
        "\n",
        "# Optional: check the result\n",
        "print(df.shape)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "WYV4RFIyalVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = jsonl_to_dataframe(\"/content/drive/MyDrive/WDC/80pair/wdcproducts80cc20rnd000un_valid_medium.json.gz\")\n"
      ],
      "metadata": {
        "id": "9Jqbb-I5F9XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_train)"
      ],
      "metadata": {
        "id": "dbrBDmpiEWJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Exchange rate mapping (to EUR)\n",
        "currency_to_eur = {\n",
        "    'EUR': 1.0, 'eur': 1.0,\n",
        "    'GBP': 1.17,\n",
        "    'USD': 0.92,\n",
        "    'CAD': 0.68,\n",
        "    'AUD': 0.61,\n",
        "    'NOK': 0.087,\n",
        "    'HUF': 0.0026,\n",
        "    'PLN': 0.23,\n",
        "    'RON': 0.20,\n",
        "    'ZAR': 0.049,\n",
        "    'SEK': 0.086,\n",
        "    'DKK': 0.13,\n",
        "    'PKR': 0.0033,\n",
        "    'UAH': 0.023,\n",
        "    'PHP': 0.016,\n",
        "    'MYR': 0.20,\n",
        "    'AED': 0.25,\n",
        "    'BRL': 0.18,\n",
        "    'CZK': 0.04, 'czk': 0.04,\n",
        "    'SGD': 0.68,\n",
        "    'VND': 0.000037,\n",
        "    'NZD': 0.57,\n",
        "    'GYD': 0.0044,\n",
        "    'HRK': 0.13,\n",
        "    'CHF': 1.03,\n",
        "    'BGN': 0.51,\n",
        "    'ILS': 0.25,\n",
        "    'ISK': 0.0065,\n",
        "    'INR': 0.011,\n",
        "    'KWD': 2.99,\n",
        "    'ARS': 0.0011,\n",
        "    'COP': 0.00023,\n",
        "    'HKD': 0.12,\n",
        "    'LEI': 0.20,  # Lei assumed same as RON\n",
        "    'CLP': 0.0010,\n",
        "    'RUB': 0.0098,\n",
        "    'IDR': 0.000059,\n",
        "    'GHS': 0.065,\n",
        "    'OMR': 2.4,\n",
        "    'MKD': 0.016,\n",
        "    'TRY': 0.028,\n",
        "    'MDL': 0.052,\n",
        "    'TND': 0.30,\n",
        "    'TZS': 0.00035,\n",
        "    'MXN': 0.052,\n",
        "    'MUR': 0.020,\n",
        "    'ALL': 0.0092,\n",
        "    'THB': 0.025,\n",
        "    'EGP': 0.019,\n",
        "    'KZT': 0.0021,\n",
        "    'BAM': 0.51,\n",
        "    'NAD': 0.049,\n",
        "    'BMD': 0.92,  # Assume USD\n",
        "    'BDT': 0.0084,\n",
        "    'JPY': 0.0062,\n",
        "    'LBP': 0.0000061,\n",
        "    'TL': 0.028,   # Turkish Lira\n",
        "    'QAR': 0.25,\n",
        "    'SAR': 0.24,\n",
        "    'BHD': 2.44,\n",
        "    'JOD': 1.30,\n",
        "    'XOF': 0.0015,\n",
        "    'NGN': 0.00059,\n",
        "    'ABC': np.nan,  # ABC not a real currency\n",
        "}\n",
        "\n",
        "# Step 2: Helper to clean price value\n",
        "def clean_price(price):\n",
        "    try:\n",
        "        if pd.isna(price):\n",
        "            return np.nan\n",
        "        return float(price)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "# Step 3: Helper to normalize price to EUR\n",
        "def normalize_price(price, currency):\n",
        "    if pd.isna(price) or pd.isna(currency):\n",
        "        return np.nan\n",
        "    rate = currency_to_eur.get(currency.strip(), None)\n",
        "    if rate is None or pd.isna(rate):\n",
        "        return np.nan  # Unknown currency\n",
        "    return price * rate\n",
        "\n",
        "# Step 4: Apply cleaning\n",
        "df['price_left'] = df['price_left'].apply(clean_price)\n",
        "df['price_right'] = df['price_right'].apply(clean_price)\n",
        "\n",
        "df['price_left_norm'] = df.apply(lambda row: normalize_price(row['price_left'], row['priceCurrency_left']), axis=1)\n",
        "df['price_right_norm'] = df.apply(lambda row: normalize_price(row['price_right'], row['priceCurrency_right']), axis=1)\n",
        "\n",
        "# Step 5: Handle missing prices smartly\n",
        "def price_difference(row):\n",
        "    p_left = row['price_left_norm']\n",
        "    p_right = row['price_right_norm']\n",
        "    if pd.notna(p_left) and pd.notna(p_right) and p_left > 0 and p_right > 0:\n",
        "        diff = abs(p_left - p_right)\n",
        "        max_price = max(p_left, p_right)\n",
        "        return diff / (max_price + 1e-5)\n",
        "    else:\n",
        "        # If any price is missing or invalid, assume maximum difference\n",
        "        return 1.0\n",
        "\n",
        "df['price_diff_norm'] = df.apply(price_difference, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "8PA-_v8pTGtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "7dmtEVI7UavD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Load your data\n",
        "\n",
        "# 2. Preprocess: Combine title and description for left and right products\n",
        "def combine_text(row, side):\n",
        "    title = str(row[f'title_{side}']) if pd.notna(row[f'title_{side}']) else ''\n",
        "    desc = str(row[f'description_{side}']) if pd.notna(row[f'description_{side}']) else ''\n",
        "    return title + \" \" + desc\n",
        "\n",
        "df['text_left'] = df.apply(lambda row: combine_text(row, 'left'), axis=1)\n",
        "df['text_right'] = df.apply(lambda row: combine_text(row, 'right'), axis=1)\n",
        "\n",
        "# 3. Build TF-IDF features\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "all_text = pd.concat([df['text_left'], df['text_right']])\n",
        "tfidf.fit(all_text)\n",
        "\n",
        "tfidf_left = tfidf.transform(df['text_left'])\n",
        "tfidf_right = tfidf.transform(df['text_right'])\n",
        "\n",
        "# 4. Compute Cosine Similarity\n",
        "cos_sim = [cosine_similarity(tfidf_left[i], tfidf_right[i])[0][0] for i in range(tfidf_left.shape[0])]\n",
        "\n"
      ],
      "metadata": {
        "id": "E82hQmhpN3nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Brand Match Feature\n",
        "def brand_match(row):\n",
        "    return int(str(row['brand_left']).lower().strip() == str(row['brand_right']).lower().strip())\n",
        "\n",
        "df['brand_match'] = df.apply(brand_match, axis=1)\n",
        "\n",
        "# 7. Assemble final feature matrix\n",
        "features = pd.DataFrame({\n",
        "    'cosine_similarity': cos_sim,\n",
        "    'price_diff_norm': df['price_diff_norm'],\n",
        "    'brand_match': df['brand_match'],\n",
        "})\n",
        "\n",
        "# Drop rows with missing values (optional)\n",
        "features = features.dropna()\n",
        "labels = df.loc[features.index, 'label']\n",
        "\n",
        "# 8. Train/Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.36, random_state=42)\n",
        "\n",
        "# 9. Train a simple Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 10. Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "qYOPz9EURpNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Exchange rate mapping (to EUR)\n",
        "currency_to_eur = {\n",
        "    'EUR': 1.0, 'eur': 1.0,\n",
        "    'GBP': 1.17,\n",
        "    'USD': 0.92,\n",
        "    'CAD': 0.68,\n",
        "    'AUD': 0.61,\n",
        "    'NOK': 0.087,\n",
        "    'HUF': 0.0026,\n",
        "    'PLN': 0.23,\n",
        "    'RON': 0.20,\n",
        "    'ZAR': 0.049,\n",
        "    'SEK': 0.086,\n",
        "    'DKK': 0.13,\n",
        "    'PKR': 0.0033,\n",
        "    'UAH': 0.023,\n",
        "    'PHP': 0.016,\n",
        "    'MYR': 0.20,\n",
        "    'AED': 0.25,\n",
        "    'BRL': 0.18,\n",
        "    'CZK': 0.04, 'czk': 0.04,\n",
        "    'SGD': 0.68,\n",
        "    'VND': 0.000037,\n",
        "    'NZD': 0.57,\n",
        "    'GYD': 0.0044,\n",
        "    'HRK': 0.13,\n",
        "    'CHF': 1.03,\n",
        "    'BGN': 0.51,\n",
        "    'ILS': 0.25,\n",
        "    'ISK': 0.0065,\n",
        "    'INR': 0.011,\n",
        "    'KWD': 2.99,\n",
        "    'ARS': 0.0011,\n",
        "    'COP': 0.00023,\n",
        "    'HKD': 0.12,\n",
        "    'LEI': 0.20,  # Lei assumed same as RON\n",
        "    'CLP': 0.0010,\n",
        "    'RUB': 0.0098,\n",
        "    'IDR': 0.000059,\n",
        "    'GHS': 0.065,\n",
        "    'OMR': 2.4,\n",
        "    'MKD': 0.016,\n",
        "    'TRY': 0.028,\n",
        "    'MDL': 0.052,\n",
        "    'TND': 0.30,\n",
        "    'TZS': 0.00035,\n",
        "    'MXN': 0.052,\n",
        "    'MUR': 0.020,\n",
        "    'ALL': 0.0092,\n",
        "    'THB': 0.025,\n",
        "    'EGP': 0.019,\n",
        "    'KZT': 0.0021,\n",
        "    'BAM': 0.51,\n",
        "    'NAD': 0.049,\n",
        "    'BMD': 0.92,  # Assume USD\n",
        "    'BDT': 0.0084,\n",
        "    'JPY': 0.0062,\n",
        "    'LBP': 0.0000061,\n",
        "    'TL': 0.028,   # Turkish Lira\n",
        "    'QAR': 0.25,\n",
        "    'SAR': 0.24,\n",
        "    'BHD': 2.44,\n",
        "    'JOD': 1.30,\n",
        "    'XOF': 0.0015,\n",
        "    'NGN': 0.00059,\n",
        "    'ABC': np.nan,  # ABC not a real currency\n",
        "}\n",
        "\n",
        "# Step 2: Helper to clean price value\n",
        "def clean_price(price):\n",
        "    try:\n",
        "        if pd.isna(price):\n",
        "            return np.nan\n",
        "        return float(price)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "# Step 3: Helper to normalize price to EUR\n",
        "def normalize_price(price, currency):\n",
        "    if pd.isna(price) or pd.isna(currency):\n",
        "        return np.nan\n",
        "    rate = currency_to_eur.get(currency.strip(), None)\n",
        "    if rate is None or pd.isna(rate):\n",
        "        return np.nan  # Unknown currency\n",
        "    return price * rate\n",
        "\n",
        "# Step 4: Apply cleaning\n",
        "df_test['price_left'] = df_test['price_left'].apply(clean_price)\n",
        "df_test['price_right'] = df_test['price_right'].apply(clean_price)\n",
        "\n",
        "df_test['price_left_norm'] = df_test.apply(lambda row: normalize_price(row['price_left'], row['priceCurrency_left']), axis=1)\n",
        "df_test['price_right_norm'] = df_test.apply(lambda row: normalize_price(row['price_right'], row['priceCurrency_right']), axis=1)\n",
        "\n",
        "# Step 5: Handle missing prices smartly\n",
        "def price_difference(row):\n",
        "    p_left = row['price_left_norm']\n",
        "    p_right = row['price_right_norm']\n",
        "    if pd.notna(p_left) and pd.notna(p_right) and p_left > 0 and p_right > 0:\n",
        "        diff = abs(p_left - p_right)\n",
        "        max_price = max(p_left, p_right)\n",
        "        return diff / (max_price + 1e-5)\n",
        "    else:\n",
        "        # If any price is missing or invalid, assume maximum difference\n",
        "        return 1.0\n",
        "\n",
        "df_test['price_diff_norm'] = df_test.apply(price_difference, axis=1)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Load your data\n",
        "\n",
        "# 2. Preprocess: Combine title and description for left and right products\n",
        "def combine_text(row, side):\n",
        "    title = str(row[f'title_{side}']) if pd.notna(row[f'title_{side}']) else ''\n",
        "    desc = str(row[f'description_{side}']) if pd.notna(row[f'description_{side}']) else ''\n",
        "    return title + \" \" + desc\n",
        "\n",
        "df_test['text_left'] = df_test.apply(lambda row: combine_text(row, 'left'), axis=1)\n",
        "df_test['text_right'] = df_test.apply(lambda row: combine_text(row, 'right'), axis=1)\n",
        "\n",
        "# 3. Build TF-IDF features\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "all_text = pd.concat([df_test['text_left'], df_test['text_right']])\n",
        "tfidf.fit(all_text)\n",
        "\n",
        "tfidf_left = tfidf.transform(df_test['text_left'])\n",
        "tfidf_right = tfidf.transform(df_test['text_right'])\n",
        "\n",
        "# 4. Compute Cosine Similarity\n",
        "cos_sim_test = [cosine_similarity(tfidf_left[i], tfidf_right[i])[0][0] for i in range(tfidf_left.shape[0])]\n",
        "\n",
        "# Step 1: Process train data\n",
        "df['brand_match'] = df.apply(brand_match, axis=1)\n",
        "\n",
        "features_train = pd.DataFrame({\n",
        "    'cosine_similarity': cos_sim,\n",
        "    'price_diff_norm': df['price_diff_norm'],\n",
        "    'brand_match': df['brand_match'],\n",
        "})\n",
        "features_train = features_train.dropna()\n",
        "labels_train = df.loc[features_train.index, 'label']\n",
        "\n",
        "# Step 2: Process test data\n",
        "df_test['brand_match'] = df_test.apply(brand_match, axis=1)\n",
        "\n",
        "features_test = pd.DataFrame({\n",
        "    'cosine_similarity': cos_sim_test,  # You need to compute this separately for df_test\n",
        "    'price_diff_norm': df_test['price_diff_norm'],\n",
        "    'brand_match': df_test['brand_match'],\n",
        "})\n",
        "features_test = features_test.dropna()\n",
        "labels_test = df_test.loc[features_test.index, 'label']\n",
        "\n",
        "# Step 3: Train on df\n",
        "model = LogisticRegression()\n",
        "model.fit(features_train, labels_train)\n",
        "\n",
        "# Step 4: Evaluate on df_test\n",
        "y_pred = model.predict(features_test)\n",
        "print(classification_report(labels_test, y_pred))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IlHwvymIGPze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Evaluate\n",
        "y_pred = model.predict(features_test)\n",
        "\n",
        "# Get misclassified examples: true label = 1, predicted = 0 (false negatives)\n",
        "false_negatives_idx = (labels_test == 1) & (y_pred == 0)\n",
        "\n",
        "# Get original examples from df_test (resetting index alignment if needed)\n",
        "df_test_reset = df_test.reset_index(drop=True)\n",
        "misclassified = df_test_reset[false_negatives_idx].head(5)\n",
        "\n",
        "# Show 5 examples\n",
        "print(misclassified[['title_left', 'title_right', 'brand_left', 'brand_right', 'price_left', 'price_right', 'label']])\n",
        "\n",
        "misclassified.to_csv('misclassified_examples.csv', index=False)\n"
      ],
      "metadata": {
        "id": "Oj7iaDydIRH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "08h4aiBmKuah"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}